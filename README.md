# ğŸ” RAG Chatbot â€“ FastAPI + Streamlit + Groq

Retrievalâ€‘Augmented Generation (RAG) chatbot that lets you **chat with your own PDFs and text files**.  
Documents are ingested, chunked, embedded, indexed with FAISS, and queried via a FastAPI backend with a Streamlit chat UI on top.

---

## âœ¨ Features

- **Domainâ€‘agnostic RAG**  
  Ingests any PDFs/TXT from `data/pdf_files/` and `data/text_files/` and answers questions over that corpus.

- **Modular RAG pipeline**
  - Document ingestion with LangChain loaders (PDF + text).
  - Recursive character chunking.
  - SentenceTransformers embeddings.
  - FAISS innerâ€‘product index for similarity search.
  - Custom `RAGRetriever` abstraction and LLM wrapper. 

- **Fullâ€‘stack app**
  - **FastAPI** backend exposing:
    - `POST /query` â€“ ask a question, get an answer + supporting contexts.
    - `POST /upload_docs` â€“ upload new PDFs/TXT and rebuild the index.
    - `GET /stats` â€“ see corpus statistics (docs, chunks, sources).
  - **Streamlit** frontend:
    - Chatâ€‘style interface (`st.chat_message`) for conversational queries.
    - Sidebar with corpus overview and document upload.

- **LLM integration (Groq)**
  - Uses Groqâ€™s `llama-3.1-8b-instant` via LangChainâ€™s `ChatGroq` for fast, instructionâ€‘following responses grounded in retrieved context. 

- **Evaluation**
  - Offline evaluation script computing **precision@5** (and recall variants) on a small labeled question set to verify retrieval quality. 

- **Designed for resumes & real projects**
  - Clean, modular structure: `rag_files/` (engine), `api/` (service), `ui/` (UI).
  - Easy to adapt to any domain: research papers, course notes, internal docs, etc.

---

## ğŸ§± Architecture Overview

      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    Documents       â”‚
      â”‚  (PDF, TXT, â€¦)     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Data Ingestion      â”‚
    â”‚  (LangChain loaders) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Chunking           â”‚
    â”‚ Recursive splitter   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Embeddings         â”‚
    â”‚ SentenceTransformers â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Vector Store       â”‚
    â”‚  FAISS (IP index)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   RAG Retriever      â”‚         â”‚     LLM (Groq)       â”‚
    â”‚  topâ€‘k relevant      â”‚ â”€â”€â”€â”€â”€â–¶  â”‚ ChatGroq, prompt     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                  â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
                  Final Answer (FastAPI â†’ Streamlit UI)


**Backâ€‘end:** `rag_files/` + `api/`  
**Frontâ€‘end:** `ui/streamlit_app.py`  

---

## ğŸ“‚ Project Structure

```text
RAG_Chatbot/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py           # FastAPI app: /query, /upload_docs, /stats
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_app.py  # Streamlit chat UI + uploads + corpus overview
â”œâ”€â”€ rag_files/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_ingestion.py # PDF/TXT loaders
â”‚   â”œâ”€â”€ chunking.py       # RecursiveCharacterTextSplitter
â”‚   â”œâ”€â”€ embeddings.py     # EmbeddingManager (SentenceTransformers)
â”‚   â”œâ”€â”€ vector_store.py   # VectorStore (FAISS IP index, docs)
â”‚   â”œâ”€â”€ retriever.py      # RAGRetriever
â”‚   â”œâ”€â”€ llm.py            # ChatGroq wrapper + prompt
â”‚   â”œâ”€â”€ pipeline.py       # RAGPipeline + get_pipeline + answer_question
â”‚   â””â”€â”€ eval.py           # precision@k (and recall) evaluation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdf_files/        # user PDFs (gitignored or small samples)
â”‚   â””â”€â”€ text_files/       # user TXT files
â”œâ”€â”€ .env.example          # example env file (no secrets)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


## âš™ï¸ Setup & Installation

## Setup

1. Clone the repository

'''bash
git clone https://github.com/ritikaugale/RAG_Chatbot.git
cd RAG_Chatbot

2. Create and activate a virtual environment

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

3. Install dependencies

pip install -r requirements.txt

4. Configure environment variables

# set your Groq key
cp .env.example .env  # if you create an example file
# edit .env and set GROQ_API_KEY=...

5. Prepare data folders 

mkdir -p data/pdf_files data/text_files

'''

## ğŸš€ Running the App
You run the backend and frontend in separate terminals (same venv).

1. Start the FastAPI backend

'''bash
uvicorn api.main:app --reload
'''

2. Start the Streamlit frontend

'''bash
streamlit run ui/streamlit_app.py
'''
